% Created 2021-01-28 Thu 17:15
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage[a4paper,margin=20mm]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{stmaryrd}
\usepackage{bm}
\usepackage{minted}
\usemintedstyle{emacs}
\usepackage[T1]{fontenc}
\usepackage[scaled]{beraserif}
\usepackage[scaled]{berasans}
\usepackage[scaled]{beramono}
\newcommand{\tr}{\textsf{T}}
\newcommand{\grad}{\bm{\nabla}}
\newcommand{\av}[2][]{\mathbb{E}_{#1\!}\left[ #2 \right]}
\newcommand{\Prob}[2][]{\mathbb{P}_{#1\!}\left[ #2 \right]}
\newcommand{\logg}[1]{\log\!\left( #1 \right)}
\newcommand{\pred}[1]{\left\llbracket { \small #1} \right\rrbracket}
\newcommand{\e}[1]{{\rm e}^{#1}}
\newcommand{\dd}{\mathrm{d}}
\DeclareMathAlphabet{\mat}{OT1}{cmss}{bx}{n}
\newcommand{\normal}[2]{\mathcal{N}\!\left(#1 \big| #2 \right)}
\newcounter{eqCounter}
\setcounter{eqCounter}{0}
\newcommand{\explanation}{\setcounter{eqCounter}{0}\renewcommand{\labelenumi}{(\arabic{enumi})}}
\newcommand{\eq}[1][=]{\stepcounter{eqCounter}\stackrel{\text{\tiny(\arabic{eqCounter})}}{#1}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\Dist}[2][Binom]{\mathrm{#1}\left( \strut {#2} \right)}
\author{Adam Prügel-Bennett}
\date{\today}
\title{Advanced Machine Learning Subsidary Notes\\\medskip
\large Lecture 5: Vector Spaces}
\hypersetup{
 pdfauthor={Adam Prügel-Bennett},
 pdftitle={Advanced Machine Learning Subsidary Notes},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.1.9)}, 
 pdflang={English}}
\begin{document}

\maketitle



\section{Keywords}
\label{sec:org0f616a7}
\begin{itemize}
\item Vectors, vector spaces, operators
\end{itemize}

\section{Main Points}
\label{sec:org7318fa3}

\subsection{Vector Spaces}
\label{sec:org40f2bb2}
\begin{itemize}
\item Any set of objects with addition between members of the set and
scalar multiplication forms a vector space if they satisfies 8 axioms
\item Most of these axioms arise naturally if addition and scale multiplication
behave normally
\item The only additional axiom is closure
\item Normal vectors, matrices and functions all form vector spaces
\end{itemize}

\subsection{Distances}
\label{sec:org782a9c9}
\begin{itemize}
\item A \emph{proper distance} or \emph{metric} between objects in a vector space
satisfies 4 conditions
\begin{enumerate}
\item \(d(\bm{x},\bm{y})\geq0\) (non-negativity)
\item \(d(\bm{x},\bm{y}) = 0\) if and only if \(\bm{x}=\bm{y}\) (identity of indiscernibles)
\item \(d(\bm{x},\bm{y}) = d(\bm{y},\bm{x})\) (symmetry)
\item \(d(\bm{x},\bm{y}) \leq d(\bm{x},\bm{z}) + d(\bm{z},\bm{y})\) (triangular inequality)
\end{enumerate}
\item You can define different distances for the same set of objects
\item Often we use \emph{pseudo-metrics} that breaks one or other of the conditions
\end{itemize}

\subsection{Norms}
\label{sec:org6f69a45}
\begin{itemize}
\item Norms provide a measure of the size of vector
\item They satisfy three conditions
\begin{enumerate}
\item \(\| \bm{v} \| >0\) if \(\bm{v}\neq\bm{0}\) (non-negativity)
\item \(\| a\,\bm{v} \| = a \| \bm{v} \|\) (linearity)
\item \(\| \bm{u} + \bm{v} \| \leq \| \bm{u} \| + \| \bm{v} \|\)  (triangular inequality)
\end{enumerate}
\item Again if not all of these conditions are true we have \emph{pseudo-norms}
\item Norms provide a metric \(d(\bm{x}, \bm{y}) = \|\bm{x}-\bm{y}\|\)
\item We will meet norms very often in this course
\item \textbf{Vector Norms}
\begin{itemize}
\item There are a large number of norms for normal vectors that people use
\begin{enumerate}
\item Euclidean or 2-norm: \(\| \bm{v} \|_2 = \sqrt{v_1^2 + v_2^2 + \cdots + v_n^2}\)
\item \(p\)-norm: \(\| \bm{v} \|_p = \left(\sum_{i=1}^n | v_i |^p \right)^{1/p}\)
\item 1-norm: \(\| \bm{v} \|_1 &= \sum\limits_{i=1}^n | v_i |\)
\item \(\infty\)-norm or max-norm: \(\| \bm{v} \|_{\infty} &= \max_i |v_i|\)
\end{enumerate}
\item Note the 1-norm, 2-norm and \(\infty\)-norm are all \(p\)-norms with different \(p\)
\item The 0-norm counts the number of non-zero components (it is a
pseudo-norm as it is not linear)
\end{itemize}
\item \textbf{Matrix Norms}
\begin{itemize}
\item Matrices also have norm
\begin{enumerate}
\item The Frobenius norm is \(\| \mat{A} \|_F = \sqrt{\sum_{i=1}^m \sum_{j=1}^n |A_{ij}|^2}\)
\item Also have 1-norm, max-norm, Hilbert-norm (the maximum absolute eigenvalue), nuclear-norm, etc.
\end{enumerate}
\item Note that the determinant is not a norm because it can be negative and is not linear
\item Many of the commonly used matrix norms satisfy
\begin{align*}
   \| \mat{A}\,\mat{B} \| \leq \| \mat{A} \| \times \| \mat{B} \|\pause
\end{align*}
\item This is really useful because we can quickly bound norms of products of matrices
\item Many matrix and vector norms are compatible
\begin{align*}
    \| \mat{M} \bm{v} \|_b \leq \| \mat{M} \|_a \times \| \bm{v} \|_b
 \end{align*}
\item E.g. Frobenius and Euclidean norms are compatible
\item One of the main uses of matrix norms is to understand by how much it
can potentially increase the size of a vector
\end{itemize}
\item \textbf{Function Norms}
\begin{itemize}
\item The most common function norms are
\begin{enumerate}
\item The \(L_2\)-norm
\begin{align*}
\| f \|_{L_2} = \sqrt{\int_{\bm{x}\in\mathcal{R}} f^2(\bm{x}) \, \dd \bm{x}}
\end{align*}
where \(\mathcal{R}\) is the region over which the function is define
\item The \(L_1\)-norm
\begin{align*}
\| f \|_{L_1} = \int_{\bm{x}\in\mathcal{R}} |f(\bm{x})| \, \dd \bm{x}
\end{align*}
\item The \(\infty\) or max-norm
\begin{align*}
\| f \|_{\infty} = \max_{\bm{x}\in\mathcal{R}} f(\bm{x})
\end{align*}
\end{enumerate}
\item Function norms are also used to define vector spaces
\begin{enumerate}
\item The \(L_2\) vector space is the set of functions such that all 
functions satisfy \(\| f \|_{L_2}<\infty\)
\item The \(L_1\) vector space is the set of functions such that all 
functions satisfy \(\| f \|_{L_1}<\infty\)
\end{enumerate}
\item In these vector spaces we only consider functions that measurable in
the sense that \(\|f\|>0\) for any non-zero function
\end{itemize}
\end{itemize}

\subsection{Inner Products}
\label{sec:orge5a6d42}
\begin{itemize}
\item For some vector spaces we can sometimes define a \emph{inner product}
\item Inner products are scalars associated with two elements in a vector space
\item They are generally denoted by \(\langle\bm{x},\bm{y}\rangle\)
\item For normal vectors the standard inner product is the dot-product
\begin{align*}
    \langle \bm{x}, \bm{y} \rangle = \bm{x}^\tr\bm{y} = \sum_{i=1}^n x_i\,y_i
\end{align*}
\item We can define an inner product between functions
\begin{align*}
  \langle f, g \rangle = \int_{x\in\mathcal{I}} f(x)\,g(x)\,\dd x\pause
\end{align*}
\item For lots of vector spaces we don't bother defining inner products 
(e.g. we don't often do this matrices)
\item Inner products allow us to define the notion of similarity
\begin{align*}
    \langle \bm{x}, \bm{y} \rangle &= \|\bm{x}\| \, \|\bm{x}\| \, \cos(\theta) \\
    \langle f(x), g(x) \rangle &= \|f(x)\| \, \|g(x)\|\, \cos(\theta)
\end{align*}
\item \(\cos(\theta)\) can be seen as a measure of the correlation between vectors (or functions)
\end{itemize}

\subsection{Coordinates or Basis Vectors}
\label{sec:orgc3f2292}
\begin{itemize}
\item Any set of vectors that span the entire vector space can be
considered a set of basis vectors or coordinates
\item If our bases are linearly independent then we have a set of
non-degenerate basis function where each vector is unique
\item The most convenient set of basis vectors are those where the
bases are normalised and orthogonal
\(\langle\bm{b}_i,\bm{b}_j\rangle=\delta_{ij}\)
\item \textbf{Basis Functions}
\begin{itemize}
\item For a function space we can consider a set of basis functions
\item A familiar set of functions define on the interval \([0,2\,\pi]\)
are the Fourier functions 
$$ \{1,\, \cos(\theta),\, \sin(\theta),\, \cos(2\,\theta),\,
       \sin(2\,\theta),\, \cdots\} $$
\item This basis set is orthogonal as for any two components \(\langle
       b_i(\theta),\,b_j(\theta)\rangle = \delta_{ij}\)
\item There are many orthogonal polynomials that have similar properties
\item Given an orthogonal set of functions \(\{b_i(\bm{x})\}\) we can decompose a function \(f(\bm{x})\)
as a (infinite) vector \(\bm{f}\) with components \(f_i = \langle f(\bm{x}),b_i(\bm{x})\rangle\)
\item This allows us to represent any function as a point in an infinite-dimensional space
\end{itemize}
\end{itemize}

\subsection{Operators}
\label{sec:orgc113393}
\begin{itemize}
\item Operators transform elements of a vector space
\item Consider the transformation or operator \(\mathcal{T}: \mathcal{V} \rightarrow \mathcal{V}'\)
\item This says that \(\mathcal{T}\) maps some object
\(\bm{x}\in\mathcal{V}\) to an object \(\bm{y}=\mathcal{T}[\bm{x}]\)
in a new vector space \(\mathcal{V}'\)
\item \textbf{Linear Operators}
\begin{itemize}
\item Linear operators satisfy the two conditions
\begin{enumerate}
\item \(\mathcal{T}[a\,\bm{x}] = a\,\mathcal{T}[\bm{x}]\)
\item \(\mathcal{T}[\bm{x} + \bm{y}] = \mathcal{T}[\bm{x}] + \mathcal{T}[\bm{y}]\)
\end{enumerate}
\item Linear operators are really important because we can understand them
\item For normal vectors the most general linear operation is
\begin{align*}
  \mathcal{T}[\bm{x}] = \mat{M}\,\bm{x}
\end{align*}
where \(\mat{M}\) is a matrix
\item For functions the most general linear operator is a kernel function
\begin{align*}
   g(\bm{x}) = \mathcal{T}[f(\bm{x})] = \int
   K(\bm{x},\bm{y})\, f(\bm{y}) \, \dd \bm{y}
\end{align*}
\begin{itemize}
\item Kernels appear in SVMs, SVRs, kernel-PCA, Gaussian Processes
\end{itemize}
\end{itemize}
\item Often we are interested in operators that map vectors in a vector space to new
vectors in the same vector space
\begin{itemize}
\item \(\mathcal{T}: \mathcal{V}\rightarrow\mathcal{V}\)
\item The most general linear mapping for normal vectors that does this are square matrices
\end{itemize}
\end{itemize}
\end{document}
