% Created 2021-01-28 Thu 17:26
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage[a4paper,margin=20mm]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{stmaryrd}
\usepackage{bm}
\usepackage{minted}
\usemintedstyle{emacs}
\usepackage[T1]{fontenc}
\usepackage[scaled]{beraserif}
\usepackage[scaled]{berasans}
\usepackage[scaled]{beramono}
\newcommand{\tr}{\textsf{T}}
\newcommand{\grad}{\bm{\nabla}}
\newcommand{\av}[2][]{\mathbb{E}_{#1\!}\left[ #2 \right]}
\newcommand{\Prob}[2][]{\mathbb{P}_{#1\!}\left[ #2 \right]}
\newcommand{\logg}[1]{\log\!\left( #1 \right)}
\newcommand{\pred}[1]{\left\llbracket { \small #1} \right\rrbracket}
\newcommand{\e}[1]{{\rm e}^{#1}}
\newcommand{\dd}{\mathrm{d}}
\DeclareMathAlphabet{\mat}{OT1}{cmss}{bx}{n}
\newcommand{\normal}[2]{\mathcal{N}\!\left(#1 \big| #2 \right)}
\newcounter{eqCounter}
\setcounter{eqCounter}{0}
\newcommand{\explanation}{\setcounter{eqCounter}{0}\renewcommand{\labelenumi}{(\arabic{enumi})}}
\newcommand{\eq}[1][=]{\stepcounter{eqCounter}\stackrel{\text{\tiny(\arabic{eqCounter})}}{#1}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\Dist}[2][Binom]{\mathrm{#1}\left( \strut {#2} \right)}
\author{Adam Prügel-Bennett}
\date{\today}
\title{Advanced Machine Learning Subsidary Notes\\\medskip
\large Lecture 15: Wasserstein GANs}
\hypersetup{
 pdfauthor={Adam Prügel-Bennett},
 pdftitle={Advanced Machine Learning Subsidary Notes},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.1.9)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section{Keywords}
\label{sec:org9ada448}
\begin{itemize}
\item GANs, Wasserstein distance, Duality, WGANs
\end{itemize}

\section{Main Points}
\label{sec:org1bbd209}
\subsection{Generative Adversarial Networks GANs}
\label{sec:orgb6fb8c4}
\begin{itemize}
\item GANs are generative models
\item They are often used for generating images or text
\begin{itemize}
\item we will consider images just to be concrete but nothing really
changes if we use text
\end{itemize}
\item The task of the GAN is to generate images from the same
distribution as those of a dataset \(\mathcal{D}\)
\item GANs use two networks
\begin{enumerate}
\item \emph{A generator network}
\begin{itemize}
\item It is fed a random vector \(\bm{z}\sim\mathcal{N}(\bm{0}, \mat{I})\)
\item They are usually networks made with fully
connected and deconvolution layers with
weights \(\bm{w}_G\)
\item They generate an "image" \(\hat{\bm{x}} = G(\bm{z}, \bm{w}_G)\)
\item We train the weights to deceive the discriminator network
\end{itemize}
\item \emph{A descriminator network}
\begin{itemize}
\item They receive either
\begin{itemize}
\item a random sample from \(\mathcal{D}\) or
\item an image \(\hat{\bm{x}}\) generated by the generator seeded
with a random vector \(\bm{z}\)
\end{itemize}
\item They are trained using backpropagation where the target
output is
\begin{itemize}
\item 1 for the real image from \(\mathcal{D}\) or
\item 0 if the input is from the generator
\end{itemize}
\item They are usually CNN networks
\end{itemize}
\end{enumerate}
\item The generator weights are also learned by back-propagation
through both the descriminator and generator networks where the
target is for the descriminator for output 1
\begin{itemize}
\item the descriminator weights aren't changed
\item this is opposite to the loss for the descriminator
\item it is fed the information about how to fool the descriminator
(i.e. how to change the elements of \(\hat{\bm{x}}\) to maximise
the output of the descriminator)
\item Hopefully over time the generator produces image more like
those from \(\mathcal{D}\)
\end{itemize}
\item \textbf{Problems with GANs}
\begin{itemize}
\item GANs are notoriously hard to train
\item The training of the descriminator and generator can become decoupled
\item For example, the descriminator can become so good that any
local change of \(\hat{\bm{x}}\) doesn't fool the descriminator
\begin{itemize}
\item but this means there is no gradient to direct the learning of
the generator
\end{itemize}
\item To overcome this we consider a very different approach
\end{itemize}
\end{itemize}

\subsection{Wasserstein Distance}
\label{sec:org726b08a}
\begin{itemize}
\item The Big Picture
\begin{itemize}
\item We consider minimising the distance between the distribution of
images generated by the generator (that is, the distribution of
\(\hat{\bm{x}} = G(\bm{z}, \bm{w}_G)\) where
\(\bm{z} \sim \mathcal{N}(\bm{0}, \mat{I})\)) and the distribution of real
images (where we consider \(\mathcal{D}\) to be a set of samples
drawn from this distribution)
\item How do we measure distances between probability distributions?
\item One of the most common methods is to use the KL-divergence
$$ \mathrm{KL}(p\|q) = \int p(\bm{x}) \,
	\logg{\frac{p(\bm{x})}{q(\bm{y})}} \, \dd \bm{x} $$
\begin{itemize}
\item Relatively nice to compute
\item Not a true distance (but that doesn't bother us)
\item Unfortunately it can get very large even when the probability
distributions are relatively close together
\end{itemize}
\end{itemize}
\item \textbf{Earth-Moving Distance}
\begin{itemize}
\item An very natural distance measure is the minimum distances you
have to move the probability mass in one distribution
\(p(\bm{x})\) to make it identical to a second distribution \(q(\bm{x})\)
\item This is also known as the \emph{Wasserstein} distance
\item Although conceptually straightforward it is a bit nasty to compute
\item \textbf{Optimal Transport Policy}
\begin{itemize}
\item We start from a transport policy \(\gamma(\bm{x},\bm{y})\) that
tells us how much probability mass (or density) we need to move
from probability distribution \(p\) at point \(\bm{x}\) to
probability distribution \(q\) at point \(\bm{y}\)
\item As we start with a distribution \(p(\bm{x})\) we need
$$ \int \gamma(\bm{x},\bm{y}) \, \dd \bm{y} &= p(\bm{x}) $$
\item As we end with a distribution \(q(\bm{x})\) we require
$$ \int \gamma(\bm{x},\bm{y}) \, \dd \bm{x} &= q(\bm{y}) $$
\item Note that \(\gamma(\bm{x},\bm{y})\) looks like a joint probability distribution
\begin{itemize}
\item It is non-negative
\item Integrating over \(\bm{x}\) and \(\bm{y}\) we get 1
\end{itemize}
\item We denote the set of probability distributions that satisfy
these constraints \(\Lambda(p,q)\)
\item The cost of a particular transport policy is
$$ C(\gamma) = \int\!\! \int d(\bm{x},\bm{y})\,\gamma(\bm{x},\bm{y}) \,
          \dd\bm{x}\,\dd\bm{y}\pause = \av[\gamma]{d(\bm{x},\bm{y})} $$
 since \(\gamma(\bm{x},\bm{y})\) is the amount of probability
mass we move and \(d(\bm{x},\bm{y})\) is the distance we move it
\item The optimal transport policy is the distribution \(\gamma \in
	 \Lambda(p,q)\) with the minimum cost
\item The cost of the optimal transport policy is the Wasserstein
distance
$$ W(p,q) = \min_{\gamma \in \Lambda(p,q)}
	 \av[\gamma]{d(\bm{x},\bm{y})} $$
\item For high dimensional probability distributions finding the
optimal transport policy using this definition is impractical
\end{itemize}
\item \textbf{Linear Programming}
\begin{itemize}
\item Computing the Wasserstein distance is a linear programming problem
\item We want to choose \(\gamma(\bm{x},\bm{y})\) to minimise a linear
objective function \(C(\gamma)\) subject to linear constraints
\item We can write this as a Lagrange problem
\begin{align*}
 \mathcal{L} = \int d(\bm{x},\bm{y})\, \gamma(\bm{x},\bm{y})
 \, \dd \bm{x}\,\dd \bm{y}
 &- \int \alpha(\bm{x}) \left( \int \gamma(\bm{x},\bm{y})\,\dd \bm{y}
- p(\bm{x})\right) \, \dd \bm{x}\\
 &- \int \beta(\bm{y}) \left( \int \gamma(\bm{x},\bm{y}) \, \dd
 \bm{x} -q(\bm{y})\right) \, \dd \bm{y}
 \end{align*}
subject to \(\gamma(\bm{x},\bm{y})\geq 0\)
\begin{itemize}
\item \(\alpha(\bm{x})\) and \(\beta(\bm{y})\) are Lagrange multiplier functions
\item This looks strange because we are used to optimise vectors
in Linear programming but here we optimise functions
\item We can discretise the function and we would get a vector
\item But functions form a vector space so  we can define a
linear programme for functions
\end{itemize}
\item \textbf{Dual Form}
\begin{itemize}
\item We can rearrange the Lagrangian as
 \begin{align*}
  \mathcal{L} = \int \alpha(\bm{x})\,p(\bm{x})\, \dd \bm{x}
+ \int \beta(\bm{y})\,q(\bm{y})\,\dd \bm{y}
  - \int \gamma(\bm{x},\bm{y})\left( \alpha(\bm{x}) + \beta(\bm{y}) -
  d(\bm{x},\bm{y})\right)\, \dd \bm{x}\,\dd \bm{y}\pause
\end{align*}
\item Now we can interpret \(\gamma(\bm{x},\bm{y})\) as a Lagrange
multiplier function so that the dual problem is
$$ \max_{\alpha(\bm{x}),\beta(\bm{x})} \; \int
           \alpha(\bm{x})\,p(\bm{x})\, \dd \bm{x} + \int 
           \beta(\bm{y})\,q(\bm{y})\,\dd \bm{y} $$
subject to
$$ \alpha(\bm{x}) + \beta(\bm{y}) \leq d(\bm{x},\bm{y}) $$
\begin{itemize}
\item note this is an inequality constraint because \(\gamma(\bm{x},\bm{y})\geq0\)
\end{itemize}
\item But this has to be true when \(\bm{x}=\bm{y}\) so
$$ \alpha(\bm{x}) + \beta(\bm{x}) \leq d(\bm{x},\bm{x}) = 0 $$
\item Thus \(\beta(\bm{x}) = -\alpha(\bm{x}) - \epsilon(\bm{x})\)
where \(\epsilon(\bm{x})\geq0\)
\item Our objective function becomes
$$  \int \alpha(\bm{x})\,p(\bm{x})\, \dd \bm{x} + \int
            \beta(\bm{y})\,q(\bm{y})\,\dd \bm{y}
            = \int \alpha(\bm{x})\,\left(p(\bm{x}) - q(\bm{x})\right) \, \dd
            \bm{x} - \int q(\bm{x}) \, \epsilon(\bm{x}) \,\dd\bm{x} $$
\item But this is clearly maximised when \(\epsilon(\bm{x})=0\)
therefore \(\beta(\bm{x}) = -\alpha(\bm{x})\)
\item The problem simplifies to 
$$ \max_{\alpha(\bm{x})} \; \int
           \alpha(\bm{x})\,p(\bm{x})\, \dd \bm{x} - \int 
           \alpha(\bm{y})\,q(\bm{y})\,\dd \bm{y} =
           \max_{\alpha(\bm{x})} \left( \av[p]{\alpha(\bm{x})} -
           \av[q]{\alpha(\bm{x})} \strut \right) $$
subject to
$$ \alpha(\bm{x}) - \alpha(\bm{y}) \leq d(\bm{x},\bm{y}) $$
\item functions \(\alpha(\bm{x})\) that satisfy this constraint are
known as \emph{Lipschitz-1 functions}
\item An equivalent condition is that
$$ \| \grad_{\bm{x}} \alpha(\bm{x}) \| \leq 1 $$
\begin{itemize}
\item this is a continuity condition saying the output has to
change slowly as we change the input
\end{itemize}
\end{itemize}
\end{itemize}
\end{itemize}
\end{itemize}

\subsection{Wasserstein GANs}
\label{sec:org65ac536}
\begin{itemize}
\item In our Wasserstein GAN we train a generator to minimise the
Wasserstein distance between the distribution of images from the
generator and the true distribution
\item We use mini-batches to approximate the expectations
  \begin{align*}
   \av[p]{\alpha(\bm{x})}
  &\approx \frac{1}{|\mathcal{B}|}
    \sum_{\bm{x}\in\mathcal{B}} \alpha(\bm{x}),
  &
    \av[q]{\alpha(\bm{x})}
  &\approx \frac{1}{n} \sum_{i=1}^n
    \alpha(G(\bm{z}_i,\bm{w}_G))\pause
\end{align*}
\item We need to find the function \(\alpha(\bm{x})\) that maximises the
difference between these expectations
\item We make \(\alpha(\bm{x})\) a neural network called the \emph{critic}
\begin{itemize}
\item this plays the same role as the discriminator in a normal GAN
\item Again we make this a CNN
\item The difference is it has to be Lipschitz-1
\item This is difficult to achieve and is usually bodged (you can
read the literature if you are interested)
\end{itemize}
\item Wasserstein GANs claim to solve many of the problems of normal
GANs
\begin{itemize}
\item They are not perfect because they only approximate the
Lipschitz-1
\end{itemize}
\item They are for me one of the elegant solutions in machine learning
of the last few years
\end{itemize}
\end{document}
