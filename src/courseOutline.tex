%Master File:lectures.tex

\lesson{Course Outline}
\vspace{-1cm}
\begin{center}
\noindent\includegraphics[height=100mm]{cnn1.jpeg}
\end{center}
\keywords{Course Details and Topics}
%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\Outline}{%
\begin{slide}
\section[1]{Outline}

\begin{minipage}{12cm}\raggedright
  \begin{enumerate}\squeeze
    \outlineitem{Course Outline}{outline}
  \end{enumerate}
\end{minipage}\hfill
\begin{minipage}{10cm}
  \includegraphics[width=10cm]{cnn1.jpeg}
\end{minipage}
\end{slide}
\addtocounter{outlineitem}{1}
}

\setcounter{outlineitem}{1}


%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%
%\Outline % Outline
\toptarget{firstoutline}
%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%

\begin{slide}
\section{Course Structure}

\begin{PauseHighLight}
  \begin{itemize}
  \item Lectures
    \begin{itemize}
    \item Tuesday 14:00-14:45 (02/1039)
    \item Thursday 16:00-16:45 (54/5025)
    \item Friday 17:00-17:45 (35/1005) \pause
    \end{itemize}
  \item Assessment
    \begin{itemize}
    \item 80\% Exam
    \item 20\% Problem Sheet\pause
    \end{itemize}
  \end{itemize}
\end{PauseHighLight}

\end{slide}

%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%

\begin{slide}
\section{Problem Sheets}

\begin{PauseHighLight}
  \begin{itemize}
  \item I am going to provide many problem sheets\pause
  \item One problem sheets will be marked and worth 20\% (you will
    know which one this is)\pause
  \item The other problem sheets are optional, but some small
    proportion of the questions will be on the exam\pause
  \item I will go through the problem sheets, but if you have not
    attempted the questions you won't learn that much\pause
  \end{itemize}
\end{PauseHighLight}

\end{slide}

%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%

\begin{slide}
  \section[-1]{What's in the Course}

  \begin{PauseHighLight}
    \begin{itemize}
    \item This course is going to cover the core principles and
      mathematics behind machine learning\pause
    \item It is not going to explicitly teach different machine
      learning algorithms\pause, although some will be covered\pauseb
    \item We are not looking at advanced algorithms but cover the
      principles\pause: fish\pauseb
    \item There are very good implementation available (e.g.{}
      scikit-learn)\pause
    \item Along the way though we will meet (often many times)
      particular algorithms\pause
    \end{itemize}
  \end{PauseHighLight}

\end{slide}

%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%

\begin{slide}
\section{Cracking the Code}

\begin{PauseHighLight}
  \begin{itemize}
  \item Mathematics is the language of machine learning\pause
  \item You can do machine learning without mathematics, but if you want
    to develop and understand advanced algorithms then you have no
    choice\pause
  \item This course invites you on a journey to crack the code of
    mathematics for machine learning\pause
  \item If this isn't a challenge you want, then this is probably not
    the course for you\pause
  \end{itemize}
\end{PauseHighLight}

\end{slide}

%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%

\begin{slide}
\section{Topics}

\begin{PauseHighLight}
  \begin{itemize}
  \item Learning Theory
    \begin{itemize}\squeeze
    \item Bias-Variance
    \item Overfitting, symmetry and regularisation
    \item Ensembling, bagging and boosting\pause
    \end{itemize}
  \item Mathematics
    \begin{itemize}\squeeze
    \item Function Spaces: Kernel Methods and Gaussian Processes
    \item Linear Algebra, embeddings, positive definiteness, subspace,
      determinants\pause
%    \item Non-linear Embeddings: tSNE\pause
    \end{itemize}
  \end{itemize}
\end{PauseHighLight}

\end{slide}

%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%

\begin{slide}
  \section[-2]{Topics Continued}

  \begin{PauseHighLight}
    \begin{itemize}
    \item Optimisation
      \begin{itemize}\squeeze
      \item Newton/Quasi-Newton Methods: convergence rates
      \item SGD, momentum, ADAM\pause
      \end{itemize}
    \item  Constrained Optimisation
      \begin{itemize}\squeeze
      \item KKT conditions
      \item Duality Linear/Quadratic Programming
      \item SVMs\pause
      \end{itemize}
    \item Convexity
      \begin{itemize}\squeeze
      \item Convex sets: linear constraints, PD matrices
      \item Convex functions
      \item SVMs, Lasso
      \item Jensen's inequality\pause
      \end{itemize}
    \end{itemize}
  \end{PauseHighLight}
\end{slide}

%%%%%%%%%%%%%%%%%%%%%%% Next Slide %%%%%%%%%%%%%%%%%%%%%%%

\begin{slide}
\section{Topics Continued}

\begin{PauseHighLight}
  \begin{itemize}
  \item Probability
    \begin{itemize}
    \item Naive Bayes
    \item Gaussian Processes
    \item Dependencies and Graphical Models
    \item Expectations and MCMC\pause
    \end{itemize}
  \item Variational Methods
    \begin{itemize}
    \item Divergences: KL and Wasserstein
    \item VAEs and GANs
    \item Entropy and information theory
    \item Variational Approximation\pause
    \end{itemize}
  \end{itemize}
\end{PauseHighLight}

\end{slide}


%%% Local Variables:
%%% TeX-master: "lectures"
%%% End:
